############################################### Setup #######################################################
version: '3.8'

volumes:
  RedisDB: { }
  Nginx: { }
  RabbitmqLog: { }
  RabbitmqLib: { }
  ElasticConfig: { }
  ElasticData: { }
  ElasticData1: { }
  ElasticData2: { }
  Kibana: { }
  Logstash: { }
  Filebeat: { }
  FilebeatData: { }
  Prometheus: { }
  PrometheusData: { }
  AlertManager: { }
  Syslog: { }
  Loki: { }
  LokiData: { }
  Promtail: { }
  GrafanaData: { }
  GrafanaConfig: { }
  ConsulConfig: { }
  ConsulData: { }
  Vault: { }

networks:
  dio:
    driver: bridge

services:
  ################################################ Hercules #######################################################
  hercules:
    build:
      context: .
      dockerfile: ./apps/hercules/Dockerfile
      target: development
    command:
      [
        'sh',
        '-c',
        'pnpm prisma generate --schema="./apps/hercules/prisma/schema.prisma" && pnpm prisma migrate dev --schema="./apps/hercules/prisma/schema.prisma" && pnpm start hercules',
      ]
    env_file: ./apps/hercules/.env
    container_name: hercules
    volumes:
      - ./apps/hercules:/usr/share/app/apps/hercules
      - ./libs:/usr/share/app/libs
      - /usr/share/app/node_modules
    expose:
      - 4000
    ports:
      - "12000:12000"
    networks:
      - dio
    restart: unless-stopped
    depends_on:
      - rabbitmq
      - hercules-db
      - redis
      - nginx
    labels:
      org.label-schema.group: 'Backend'

  hercules-db:
    image: postgres:14-alpine
    container_name: hercules-db
    ports:
      - "5433:5432"
    networks:
      - dio
    environment:
      POSTGRES_USER: ares
      POSTGRES_PASSWORD: 7142
      POSTGRES_DB: hercules

  redis:
    image: redis:alpine
    container_name: redis
    expose:
      - 6379
    volumes:
      - RedisDB:/data
    networks:
      dio:
    labels:
      org.label-schema.group: 'Api'

  ################################################ Apollo #######################################################
  apollo:
    build:
      context: .
      dockerfile: ./apps/apollo/Dockerfile
      target: development
    #      args:
    #        - ${APOLLO_DATABASE_URL}
    command:
      [
        'sh',
        '-c',
        'pnpm prisma generate --schema="./apps/apollo/prisma/schema.prisma" && pnpm prisma migrate dev --schema="./apps/apollo/prisma/schema.prisma" && pnpm run start apollo',
      ]
    env_file: ./apps/apollo/.env
    container_name: apollo
    ports:
      - '4001:4001'
      - '5555:5555'
    networks:
      - dio
    restart: unless-stopped
    labels:
      org.label-schema.group: 'Apollo'
    volumes:
      - ./apps/apollo:/usr/share/app/apps/apollo
      - ./libs:/usr/share/app/libs
      - /usr/share/app/node_modules
    depends_on:
      - apollo-db
      - rabbitmq

  apollo-db:
    image: postgres:14-alpine
    container_name: apollo-db
    ports:
      - "5434:5432"
    networks:
      - dio
    environment:
      POSTGRES_USER: ares
      POSTGRES_PASSWORD: 7142
      POSTGRES_DB: apollo

  ################################################ Coeus #######################################################
  coeus:
    build:
      context: .
      dockerfile: ./apps/coeus/Dockerfile
      target: development
    command: [ 'sh', '-c', 'pnpm run start coeus' ]
    env_file: ./apps/coeus/.env
    container_name: coeus
    ports:
      - '4002:4002'
    networks:
      - dio
    restart: unless-stopped
    labels:
      org.label-schema.group: 'Coeus'
    volumes:
      - ./apps/coeus:/usr/share/app/apps/coeus
      - ./libs:/usr/share/app/libs
      - /usr/share/app/node_modules
    depends_on:
      - rabbitmq
      - zeus

  ############################################## Athena ########################################################
  athena:
    build:
      context: ./athena
      dockerfile: Dockerfile
    container_name: athena
    expose:
      - 4003
    networks:
      dio:
    restart: unless-stopped
    labels:
      org.label-schema.group: 'Athena'

  ############################################## Hesita ########################################################
  hesita:
    build:
      context: .
      dockerfile: ./apps/hesita/Dockerfile
      target: development
    command: [ 'sh', '-c', 'pnpm run start hesita' ]
    env_file: ./apps/hesita/.env
    container_name: hesita
    ports:
      - '4004:4004'
    networks:
      - dio
    restart: unless-stopped
    labels:
      org.label-schema.group: 'Hesita'
    volumes:
      - ./apps/hesita:/usr/share/app/apps/hesita
      - ./libs:/usr/share/app/libs
      - /usr/share/app/node_modules
    depends_on:
      - rabbitmq

  ############################################## Elastic ########################################################
  zeus:
    build:
      context: ./elk/elasticsearch
      dockerfile: Dockerfile
      args:
        ELK_VERSION: ${ELK_VERSION}
    container_name: zeus
    restart: unless-stopped
    environment:
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      ELASTIC_CLUSTER_NAME: ${ELASTIC_CLUSTER_NAME}
      ELASTIC_NODE_NAME: ${ELASTIC_NODE_NAME}
      ELASTIC_INIT_MASTER_NODE: ${ELASTIC_INIT_MASTER_NODE}
      ELASTIC_DISCOVERY_SEEDS: ${ELASTIC_DISCOVERY_SEEDS}
      ES_JAVA_OPTS: '-Xmx${ELASTICSEARCH_HEAP} -Xms${ELASTICSEARCH_HEAP} -Des.enforce.bootstrap.checks=true -Dlog4j2.formatMsgNoLookups=true'
      bootstrap.memory_lock: 'true'
    volumes:
      - ElasticData:/usr/share/elasticsearch/data
      - ElasticConfig:/usr/share/elasticsearch/config
    ports:
      - '9200:9200'
      - '9300:9300'
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 100000
        hard: 100000
    networks:
      - dio
    # healthcheck:
    #   test:
    #     [
    #       'CMD',
    #       'sh',
    #       '-c',
    #       "curl -sf --insecure https://$ELASTIC_USERNAME:$ELASTIC_PASSWORD@localhost:9200/_cat/health | grep -ioE 'green|yellow' || echo 'not green/yellow cluster status'",
    #     ]

  elasticsearch_poseidon:
    build:
      context: ./elk/elasticsearch
      dockerfile: Dockerfile
      args:
        ELK_VERSION: ${ELK_VERSION}
    container_name: elasticsearch_poseidon
    restart: unless-stopped
    environment:
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      ELASTIC_CLUSTER_NAME: ${ELASTIC_CLUSTER_NAME}
      ELASTIC_NODE_NAME: ${ELASTIC_NODE_NAME_1}
      ELASTIC_INIT_MASTER_NODE: ${ELASTIC_INIT_MASTER_NODE}
      ELASTIC_DISCOVERY_SEEDS: ${ELASTIC_DISCOVERY_SEEDS}
      ES_JAVA_OPTS: "-Xmx${ELASTICSEARCH_HEAP} -Xms${ELASTICSEARCH_HEAP} -Des.enforce.bootstrap.checks=true -Dlog4j2.formatMsgNoLookups=true"
      bootstrap.memory_lock: "true"
    volumes:
      - ElasticData1:/usr/share/elasticsearch/data
      - ElasticConfig:/usr/share/elasticsearch/config
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 200000
        hard: 200000
    networks:
      - dio
    # healthcheck:
    #   test: ["CMD", "sh", "-c", "curl -sf --insecure https://$ELASTIC_USERNAME:$ELASTIC_PASSWORD@localhost:9200/_cat/health | grep -ioE 'green|yellow' || echo 'not green/yellow cluster status'"]

  elasticsearch_hades:
    build:
      context: ./elk/elasticsearch
      dockerfile: Dockerfile
      args:
        ELK_VERSION: ${ELK_VERSION}
    container_name: elasticsearch_hades
    restart: unless-stopped
    environment:
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      ELASTIC_CLUSTER_NAME: ${ELASTIC_CLUSTER_NAME}
      ELASTIC_NODE_NAME: ${ELASTIC_NODE_NAME_1}
      ELASTIC_INIT_MASTER_NODE: ${ELASTIC_INIT_MASTER_NODE}
      ELASTIC_DISCOVERY_SEEDS: ${ELASTIC_DISCOVERY_SEEDS}
      ES_JAVA_OPTS: "-Xmx${ELASTICSEARCH_HEAP} -Xms${ELASTICSEARCH_HEAP} -Des.enforce.bootstrap.checks=true -Dlog4j2.formatMsgNoLookups=true"
      bootstrap.memory_lock: "true"
    volumes:
      - ElasticData2:/usr/share/elasticsearch/data
      - ElasticConfig:/usr/share/elasticsearch/config
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 200000
        hard: 200000
    networks:
      - dio
    # healthcheck:
    #   test: ["CMD", "sh", "-c", "curl -sf --insecure https://$ELASTIC_USERNAME:$ELASTIC_PASSWORD@localhost:9200/_cat/health | grep -ioE 'green|yellow' || echo 'not green/yellow cluster status'"]

  kibana:
    build:
      context: ./elk/kibana
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: kibana
    restart: unless-stopped
    volumes:
      - Kibana:/usr/share/kibana
    environment:
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      ELASTICSEARCH_HOST_PORT: https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}
    ports:
      - '5601:5601'
    networks:
      - dio

  logstash:
    build:
      context: ./elk/logstash
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: logstash
    restart: unless-stopped
    volumes:
      - Logstash:/usr/share/logstash
    environment:
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      ELASTICSEARCH_HOST_PORT: https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}
      LS_JAVA_OPTS: "-Xmx${LOGSTASH_HEAP} -Xms${LOGSTASH_HEAP} -Dlog4j2.formatMsgNoLookups=true"
    ports:
      - "5044:5044"
      - "9600:9600"
    networks:
      - dio
    # healthcheck:
    #   test: ["CMD", "sh", "-c", "curl -sf --insecure https://$ELASTIC_USERNAME:$ELASTIC_PASSWORD@localhost:9200/_cat/health | grep -ioE 'green|yellow' || echo 'not green/yellow cluster status'"]

  filebeat:
    build:
      context: ./elk/filebeat
      args:
        ELK_VERSION: $ELK_VERSION
    restart: always
    command: -e --strict.perms=false
    user: root
    container_name: filebeat
    environment:
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      KIBANA_HOST_PORT: ${KIBANA_HOST}:${KIBANA_PORT}
      ELASTICSEARCH_HOST_PORT: https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}
    expose:
      - 5066
    volumes:
      - Filebeat:/usr/share/filebeat
      - FilebeatData:/var/lib/filebeat/data
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro‚èé
    networks:
      - dio

  rubban:
    image: sherifabdlnaby/rubban:latest
    restart: unless-stopped
    container_name: rubban
    environment:
      RUBBAN_KIBANA_HOST: "https://${KIBANA_HOST}:${KIBANA_PORT}"
      RUBBAN_KIBANA_USER: ${ELASTIC_USERNAME}
      RUBBAN_KIBANA_PASSWORD: ${ELASTIC_PASSWORD}
      RUBBAN_REFRESHINDEXPATTERN_ENABLED: "true"
      RUBBAN_REFRESHINDEXPATTERN_SCHEDULE: "*/5 * * * *"
      RUBBAN_REFRESHINDEXPATTERN_PATTERNS: "*"
      RUBBAN_AUTOINDEXPATTERN_ENABLED: "true"
      RUBBAN_AUTOINDEXPATTERN_SCHEDULE: "*/5 * * * *"
      RUBBAN_AUTOINDEXPATTERN_GENERALPATTERNS: '[{"pattern":"filebeat?","timeFieldName":"@timestamp"},{"pattern":"logstash?","timeFieldName":"@timestamp"}]'

  elasticsearch-exporter:
    container_name: elasticsearch_exporter
    image: justwatch/elasticsearch_exporter:1.1.0
    restart: always
    command:
      [
        "--es.uri",
        "https://${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}@${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}",
        "--es.ssl-skip-verify",
        "--es.all",
        "--es.snapshots",
        "--es.indices",
      ]
    ports:
      - "9114:9114"

  logstash-exporter:
    image: alxrem/prometheus-logstash-exporter:0.7.0
    container_name: logstash_exporter
    restart: always
    ports:
      - "9304:9304"
    command: [ "-logstash.host", "logstash" ]
    networks:
      - dio

  ############################################ Monitoring #######################################################
  ### v9.0.2
  grafana:
    build:
      context: ./monitoring/grafana
      dockerfile: Dockerfile
    container_name: grafana
    volumes:
      - GrafanaData:/var/lib/grafana
      - GrafanaConfig:/etc/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    restart: unless-stopped
    ports:
      - '3000:3000'
    networks:
      - dio
    labels:
      org.label-schema.group: 'Visualization'

  ### v2.36.2
  prometheus:
    build:
      context: ./monitoring/prometheus
      dockerfile: Dockerfile
    container_name: prometheus
    expose:
      - 9090
    networks:
      - dio
    volumes:
      - Prometheus:/etc/prometheus
      - PrometheusData:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    labels:
      org.label-schema.group: 'monitoring'

  ### v0.24.0
  alertmanager:
    build:
      context: ./monitoring/alertmanager
      dockerfile: Dockerfile
    container_name: alertmanager
    volumes:
      - AlertManager:/etc/alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    restart: unless-stopped
    expose:
      - 9093
    networks:
      - dio
    labels:
      org.label-schema.group: 'monitoring'

  ### v0.44.0
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.44.0
    container_name: cadvisor
    privileged: true
    devices:
      - /dev/kmsg:/dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
    restart: unless-stopped
    expose:
      - 8080
    networks:
      - dio
    labels:
      org.label-schema.group: 'monitoring'

  ### v1.4.3
  pushgateway:
    image: prom/pushgateway:v1.4.3
    container_name: pushgateway
    restart: unless-stopped
    expose:
      - 9091
    networks:
      - dio
    labels:
      org.label-schema.group: 'monitoring'

  ### v1.3.1
  nodeexporter:
    image: prom/node-exporter:v1.3.1
    container_name: nodeexporter
    user: root
    privileged: true
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    expose:
      - 9100
    networks:
      - dio
    labels:
      org.label-schema.group: 'monitoring'

  ### 0.10
  nginxexporter:
    image: nginx/nginx-prometheus-exporter:0.10
    container_name: nginx-exporter
    expose:
      - 9113
    command:
      - -nginx.scrape-uri
      - http://nginx:8081/stub_status
    restart: unless-stopped
    networks:
      - dio
    labels:
      org.label-schema.group: 'monitoring'

  ################################################## Logging ######################################################
  ### v2.5.0
  loki:
    build:
      context: ./monitoring/loki
      dockerfile: Dockerfile
    container_name: loki
    privileged: true
    user: root
    volumes:
      - Loki:/etc/loki
      - LokiData:/tmp/loki
    command: -config.file=/etc/loki/loki-config.yml
    restart: always
    expose:
      - 3100
    networks:
      dio:
    labels:
      org.label-schema.group: 'logging'

  ### v2.5.0
  promtail:
    build:
      context: ./monitoring/promtail
      dockerfile: Dockerfile
    user: root
    privileged: true
    container_name: promtail
    command: -config.file=/etc/promtail/promtail-config.yml
    volumes:
      - Promtail:/etc/promtail
      - /var/log:/var/log
      - /var/lib/docker/containers:/var/lib/docker/containers
    expose:
      - 9080
      - 1514
    networks:
      dio:
    restart: unless-stopped
    labels:
      org.label-schema.group: 'logging'

  # v3.30.1
  syslog-ng:
    build:
      context: ./monitoring/syslog
      dockerfile: Dockerfile
    container_name: syslog-ng
    user: root
    privileged: true
    volumes:
      - Syslog:/etc/syslog-ng
      - /var/log:/var/log
    networks:
      dio:
    ports:
      - protocol: udp
        published: 514
        target: 514
      - protocol: tcp
        published: 601
        target: 601
    restart: always
    labels:
      org.label-schema.group: 'logging'

  ################################################# System ########################################################
  ### v1.23.0-alpine
  nginx:
    build:
      context: ./nginx
      dockerfile: Dockerfile
    container_name: nginx
    ports:
      - '3000:3000'
      - '3100:3100'
      - '4000:4000'
      - '5601:5601'
      - '8081:8081'
    volumes:
      #      - Nginx:/etc/nginx
      - ./nginx:/etc/nginx
    networks:
      - dio
    restart: unless-stopped
    labels:
      org.label-schema.group: 'System'

  rabbitmq:
    image: rabbitmq:3.9.22-management-alpine
    container_name: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - RabbitmqLib:/var/lib/rabbitmq/
      - RabbitmqLog:/var/log/rabbitmq
    networks:
      - dio
    labels:
      org.label-schema.group: 'System'

  ### v1.5.0
  vault:
    build:
      context: ./secrets/vault
      dockerfile: Dockerfile
    container_name: vault
    ports:
      - "8200:8200"
    volumes:
      - Vault:/vault
    environment:
      - VAULT_ADDR=http://127.0.0.1:8200
    command: server
    cap_add:
      - IPC_LOCK
    depends_on:
      - consul
    networks:
      - dio
    labels:
      org.label-schema.group: "System"

  ### v1.8.2
  consul:
    build:
      context: ./secrets/consul
      dockerfile: Dockerfile
    container_name: consul
    ports:
      - "8500:8500"
    environment:
      - CONSUL_BIND_INTERFACE=eth0
      - CONSUL_CLIENT_INTERFACE=eth0
      - CONSUL_ALLOW_PRIVILEGED_PORTS=
    command: agent -server -bootstrap-expect 1
    volumes:
      - ConsulConfig:/consul/config
      - ConsulData:/consul/data
    networks:
      - dio
    labels:
      org.label-schema.group: "System"
################################################################################################################
