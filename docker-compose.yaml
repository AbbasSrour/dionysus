############################################### Setup #######################################################
version: "3.8"

volumes:
  RedisDB:
  Prometheus: {}
  PrometheusData: {}
  GrafanaData: {}
  GrafanaConfig: {}
  Caddy: {}
  AlertManager: {}
  Syslog: {}
  Loki: {}
  LokiData: {}
  Promtail: {}
  ConsulConfig: {}
  ConsulData: {}
  Vault: {}
  Nginx: {}
  ElasticData: {}
  ElasticConfig: {}
  Kibana: {}
  Filebeat: {}
  LogstashConfig: {}
  LogstashPipes: {}
  elasticsearch: {}

networks:
  elk:
  monitor-net:
    driver: bridge

services:
################################################ Api #######################################################
  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: api
    expose:
      - 5000
      - 9229
    networks:
      monitor-net:
    restart: unless-stopped
    labels:
      org.label-schema.group: "Api"

  redis:
    image: redis:alpine
    container_name: redis
    expose:
      - 6379
    volumes:
      - RedisDB:/data
    networks:
      monitor-net:
    labels:
      org.label-schema.group: "Api"
############################################## Search Engine ########################################################
########################## Base
  elasticsearch:
    build:
      context: ./server/elk/elasticsearch
      dockerfile: Dockerfile
    container_name: elasticsearch
    restart: unless-stopped
    environment:
      ELASTIC_USERNAME: elastic
      ELASTIC_PASSWORD: changeme
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      discovery.type: single-node
      # bootstrap.memory_lock: "true"
    volumes:
      - ElasticData:/usr/share/elasticsearch/data
      - ElasticConfig:/usr/share/elasticsearch/config
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - monitor-net

  # logstash:
  #   build:
  #     context: ./server/elk/logstash
  #   container_name: logstash
  #   restart: unless-stopped
  #   volumes:
  #     - LogstashConfig:/usr/share/logstash/config
  #     - LogstashPipes:/usr/share/logstash/pipeline
  #   environment:
  #     ELASTIC_USERNAME: ${ELASTIC_USERNAME}
  #     ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
  #     ELASTICSEARCH_HOST_PORT: http://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}
  #     LS_JAVA_OPTS: "-Xmx${LOGSTASH_HEAP} -Xms${LOGSTASH_HEAP} -Dlog4j2.formatMsgNoLookups=true"
  #   ports:
  #     - "5044:5044"
  #     - "9600:9600"


  kibana:
    build:
      context: ./server/elk/kibana
    container_name: kibana
    restart: unless-stopped
    volumes:
      - Kibana:/usr/share/kibana
    environment:
      ELASTIC_USERNAME: elastic
      ELASTIC_PASSWORD: changeme
      ELASTICSEARCH_HOST_PORT: http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - monitor-net

  # rubban:
  #   image: sherifabdlnaby/rubban:latest
  #   restart: unless-stopped
  #   container_name: rubban
  #   environment:
  #     RUBBAN_KIBANA_HOST: "https://${KIBANA_HOST}:${KIBANA_PORT}"
  #     RUBBAN_KIBANA_USER: ${ELASTIC_USERNAME}
  #     RUBBAN_KIBANA_PASSWORD: ${ELASTIC_PASSWORD}
  #     RUBBAN_REFRESHINDEXPATTERN_ENABLED: 'true'
  #     RUBBAN_REFRESHINDEXPATTERN_SCHEDULE: '*/5 * * * *'
  #     RUBBAN_REFRESHINDEXPATTERN_PATTERNS: '*'
  #     RUBBAN_AUTOINDEXPATTERN_ENABLED: 'true'
  #     RUBBAN_AUTOINDEXPATTERN_SCHEDULE: '*/5 * * * *'
  #     RUBBAN_AUTOINDEXPATTERN_GENERALPATTERNS: '[{"pattern":"filebeat?","timeFieldName":"@timestamp"},{"pattern":"logstash?","timeFieldName":"@timestamp"}]'

  # Prometheus Exporters ----
  # elasticsearch-exporter:
  #   container_name: elasticsearch_exporter
  #   image: justwatch/elasticsearch_exporter:1.1.0
  #   restart: always
  #   command: ["--es.uri", "https://${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}@${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}",
  #             "--es.ssl-skip-verify",
  #             "--es.all",
  #             "--es.snapshots",
  #             "--es.indices"]
  #   ports:
  #     - "9114:9114"

  # Logstash Exporters ----
  # logstash-exporter:
  #   image: alxrem/prometheus-logstash-exporter:0.7.0
  #   container_name: logstash_exporter
  #   restart: always
  #   ports:
  #     - "9304:9304"
  #   command: ["-logstash.host", "${LOGSTASH_HOST}"]

  # # Docker Logs Shipper ------------------------------
  # filebeat:
  #   image: elastic/filebeat:${ELK_VERSION}
  #   build:
  #     context: ./server/elk/filebeat
  #   restart: always
  #   # -e flag to log to stderr and disable syslog/file output
  #   command: -e --strict.perms=false
  #   user: root
  #   environment:
  #     ELASTIC_USERNAME: ${ELASTIC_USERNAME}
  #     ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
  #     KIBANA_HOST_PORT: ${KIBANA_HOST}:${KIBANA_PORT}
  #     ELASTICSEARCH_HOST_PORT: https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}
  #   volumes:
  #     - ./filebeat/filebeat.docker.logs.yml:/usr/share/filebeat/filebeat.yml:ro
  #     - /var/lib/docker/containers:/var/lib/docker/containers:ro
  #     - /var/run/docker.sock:/var/run/docker.sock:ro
  #     - filebeat-data:/var/lib/filebeat/data

  # # # Cluster Logs Shipper ----
  # filebeat-cluster-logs:
  #   image: docker.elastic.co/beats/filebeat:8.3.2
  #   build:
  #     context: ./server/elk/filebeat
  #   restart: always
  #   # -e flag to log to stderr and disable syslog/file output
  #   command: -e --strict.perms=false
  #   user: root
  #   environment:
  #     ELASTIC_USERNAME: ${ELASTIC_USERNAME}
  #     ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
  #     KIBANA_HOST_PORT: ${KIBANA_HOST}:${KIBANA_PORT}
  #     ELASTICSEARCH_HOST_PORT: https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}
  #   volumes:
  #     - Filebeat:/usr/share/filebeat
  #     - /var/lib/docker/containers:/var/lib/docker/containers:ro
  #     - /var/run/docker.sock:/var/run/docker.sock:ro

############################################ Monitoring #######################################################
### v2.36.2
  prometheus:
    build: 
      context: ./server/monitoring/prometheus
      dockerfile: Dockerfile
    container_name: prometheus
    expose:
      - 9090
    networks:
      - monitor-net
    volumes:
      - Prometheus:/etc/prometheus
      - PrometheusData:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    labels:
      org.label-schema.group: "monitoring"

### v0.24.0
  alertmanager:
    build: 
      context: ./server/monitoring/alertmanager
      dockerfile: Dockerfile
    container_name: alertmanager
    volumes:
      - AlertManager:/etc/alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    restart: unless-stopped
    expose:
      - 9093
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

### v0.44.0
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.44.0
    container_name: cadvisor
    privileged: true
    devices:
      - /dev/kmsg:/dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
    restart: unless-stopped
    expose:
      - 8080
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

### v1.4.3
  pushgateway:
    image: prom/pushgateway:v1.4.3
    container_name: pushgateway
    restart: unless-stopped
    expose:
      - 9091
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

### v1.3.1
  nodeexporter:
    image: prom/node-exporter:v1.3.1
    container_name: nodeexporter
    user: root
    privileged: true
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    expose:
      - 9100
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

### 0.10
  nginxexporter:
    image: nginx/nginx-prometheus-exporter:0.10
    container_name: nginx-exporter
    expose:
      - 9113
    command: 
      - -nginx.scrape-uri
      - http://nginx:8081/stub_status
    restart: unless-stopped
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

################################################## Logging ######################################################
### v2.5.0
  loki:
    build:
      context: ./server/monitoring/loki
      dockerfile: Dockerfile
    container_name: loki
    privileged: true
    user: root
    volumes:
      - Loki:/etc/loki
      - LokiData:/tmp/loki
    command: -config.file=/etc/loki/loki-config.yml
    restart: always
    expose:
      - 3100
    networks:
      monitor-net:
    labels:
      org.label-schema.group: "logging"

### v2.5.0
  promtail:
    build:
      context: ./server/monitoring/promtail
      dockerfile: Dockerfile
    user: root
    privileged: true
    container_name: promtail
    command: -config.file=/etc/promtail/promtail-config.yml
    volumes:
      - Promtail:/etc/promtail
      - /var/log:/var/log
      - /var/lib/docker/containers:/var/lib/docker/containers
    expose:
      - 9080
      - 1514
    networks:
      monitor-net:
    restart: unless-stopped
    labels:
      org.label-schema.group: "logging"
  
# v3.30.1
  syslog-ng:
    build: 
      context: ./server/monitoring/syslog
      dockerfile: Dockerfile
    container_name: syslog-ng
    user: root
    privileged: true
    volumes:
      - Syslog:/etc/syslog-ng
      - /var/log:/var/log
    networks:
      monitor-net:
    ports:
      - protocol: udp
        published: 514
        target: 514
      - protocol: tcp
        published: 601
        target: 601
    restart: always
    labels:
      org.label-schema.group: "logging"

############################################## Visualization ###################################################
### v9.0.2
  grafana:
    build: 
      context: ./server/monitoring/grafana
      dockerfile: Dockerfile
    container_name: grafana
    volumes:
      - GrafanaData:/var/lib/grafana
      - GrafanaConfig:/etc/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    restart: unless-stopped
    expose:
      - 3000
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "Visualization"

################################################# System ########################################################
# ### v1.5.0
#   vault:
#     build: 
#       context: ./server/secrets/vault
#       dockerfile: Dockerfile
#     container_name: vault
#     ports:
#       - 8200:8200
#     volumes:
#       - Vault:/vault
#     environment:
#       - VAULT_ADDR=http://127.0.0.1:8200
#     command: server
#     cap_add:
#       - IPC_LOCK
#     depends_on:
#       - consul
#     networks:
#       - monitor-net
#     labels:
#       org.label-schema.group: "System"

# ### v1.8.2
#   consul:
#     build: 
#       context: ./server/secrets/consul
#       dockerfile: Dockerfile
#     container_name: consul
#     ports:
#       - 8500:8500
#     environment:
#       - CONSUL_BIND_INTERFACE=eth0
#       - CONSUL_CLIENT_INTERFACE=eth0
#       - CONSUL_ALLOW_PRIVILEGED_PORTS=
#     command: agent -server -bootstrap-expect 1
#     volumes:
#       - ConsulConfig:/consul/config
#       - ConsulData:/consul/data
#     networks:
#       - monitor-net
#     labels:
#       org.label-schema.group: "System"

### v1.23.0-alpine
  nginx:
    build: 
      context: ./server/nginx
      dockerfile: Dockerfile
    container_name: nginx
    ports:
      - "4000:80"
      - "3000:3000"
      - "3100:3100"
      - "5000:5000"
      - "8081:8081"

    volumes:
      - Nginx:/etc/nginx
    networks:
      - monitor-net
    restart: unless-stopped
    labels:
      org.label-schema.group: "System"
################################################################################################################